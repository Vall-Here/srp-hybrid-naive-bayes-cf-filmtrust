{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03509a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array([\n",
    "    [0, 1, 2, 2, 5, 0, 4, 3, 5], \n",
    "    [1, 5, 3, 0, 2, 3, 4, 3, 0], \n",
    "    [1, 1, 2, 0, 2, 4, 4, 5, 0], \n",
    "    [3, 2, 2, 3, 0, 1, 3, 2, 0], \n",
    "    [5, 1, 5, 5, 4, 4, 5, 2, 0], \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc453f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[1][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea0b97",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857361fd",
   "metadata": {},
   "source": [
    "# Toy Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e80513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0345d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array([\n",
    "    [0, 1, 2, 2, 5, 0, 4, 3, 5], \n",
    "    [1, 5, 3, 0, 2, 3, 4, 3, 0], \n",
    "    [1, 1, 2, 0, 2, 4, 4, 5, 0], \n",
    "    [3, 2, 2, 3, 0, 1, 3, 2, 0], \n",
    "    [5, 1, 5, 5, 4, 4, 5, 2, 0], \n",
    "])\n",
    "\n",
    "\n",
    "def compute_priors(ratings, alpha=0.01, R=5):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    rating_values = list(range(1, R + 1))\n",
    "\n",
    "    prior_userbased = [[0 for _ in range(num_items)] for _ in rating_values]\n",
    "    prior_itembased = [[0 for _ in range(num_users)] for _ in rating_values]\n",
    "\n",
    "    for y in rating_values:\n",
    "        y_index = y - 1\n",
    "\n",
    "        # Prior user-based (per item j)\n",
    "        for j in range(num_items):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for u in range(num_users):\n",
    "                r = ratings[u][j]\n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_userbased[y_index][j] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "\n",
    "        # Prior item-based (per user u)\n",
    "        for u in range(num_users):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for j in range(num_items):\n",
    "                r = ratings[u][j]\n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_itembased[y_index][u] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "\n",
    "    return prior_userbased, prior_itembased\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10750957",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_userbased, prior_itembased = compute_priors(ratings)\n",
    "prior_userbased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_userbased(ratings, u, i, y, alpha=0.01, R=5):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Iu = [j for j in range(num_items) if j != i and ratings[u][j] != 0]\n",
    "    product = 1.0\n",
    "\n",
    "    for j in Iu:\n",
    "        k = ratings[u][j]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        for v in range(num_users):\n",
    "            if ratings[v][i] == y:\n",
    "                if ratings[v][j] != 0:\n",
    "                    count_cond += 1\n",
    "                    if ratings[v][j] == k:\n",
    "                        count_joint += 1\n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        print(prob)\n",
    "        product *= prob\n",
    "    print(\"======\")\n",
    "    print(product, end=\"\\n\\n\")\n",
    "\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16757908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_itembased(ratings, u, i, y, alpha=0.01, R=5):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Ui = [v for v in range(num_users) if v != u and ratings[v][i] != 0]\n",
    "    product = 1.0\n",
    "\n",
    "    for v in Ui:\n",
    "        k = ratings[v][i]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        for j in range(num_items):\n",
    "            if ratings[u][j] == y:\n",
    "                if ratings[v][j] != 0:\n",
    "                    count_cond += 1\n",
    "                    if ratings[v][j] == k:\n",
    "                        count_joint += 1\n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        product *= prob\n",
    "\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8de187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for y in range(1, 5 + 1):\n",
    "#     y_index = y - 1\n",
    "\n",
    "#     likelihood_user = compute_likelihood_userbased(ratings, 0, 0, y)\n",
    "    \n",
    "#     # likelihood_item = compute_likelihood_itembased(ratings, 1, 1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(ratings, u, i, prior_userbased, prior_itembased, alpha=0.01, R=5, mode='hybrid'):\n",
    "    scores = []\n",
    "    all_likelihood_user = []  \n",
    "    all_likelihood_item = []\n",
    "    all_combined = []  \n",
    "\n",
    "    for y in range(1, R + 1):\n",
    "        y_index = y - 1\n",
    "        prior_user = prior_userbased[y_index][i]\n",
    "        prior_item = prior_itembased[y_index][u]\n",
    "\n",
    "        likelihood_user = compute_likelihood_userbased(ratings, u, i, y, alpha, R)\n",
    "        likelihood_item = compute_likelihood_itembased(ratings, u, i, y, alpha, R)\n",
    "\n",
    "        all_likelihood_user.append(likelihood_user)\n",
    "        all_likelihood_item.append(likelihood_item)\n",
    "\n",
    "        if mode == 'user':\n",
    "            score = prior_user * likelihood_user\n",
    "        elif mode == 'item':\n",
    "            score = prior_item * likelihood_item\n",
    "        else:  # hybrid\n",
    "            len_Iu = sum(1 for j in range(len(ratings[0])) if ratings[u][j] != 0 and j != i)\n",
    "            len_Ui = sum(1 for v in range(len(ratings)) if v != u and ratings[v][i] != 0)\n",
    "\n",
    "            score_user = (prior_user * likelihood_user) ** (1 / (1 + len_Iu)) if len_Iu > 0 else 0\n",
    "            score_item = (prior_item * likelihood_item) ** (1 / (1 + len_Ui)) if len_Ui > 0 else 0\n",
    "            score = score_user * score_item\n",
    "\n",
    "        scores.append(score)\n",
    "        all_combined.append(score)\n",
    "\n",
    "    predicted_rating = scores.index(max(scores)) + 1\n",
    "\n",
    "    return predicted_rating, {\n",
    "        'scores': scores,\n",
    "        'likelihood_user': all_likelihood_user,\n",
    "        'likelihood_item': all_likelihood_item,\n",
    "        'combined_score': all_combined\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating, details = predict_rating(\n",
    "    ratings, u=0, i=0,\n",
    "    prior_userbased=prior_userbased,\n",
    "    prior_itembased=prior_itembased,\n",
    "    mode='hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "details['likelihood_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9938e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "details['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60309d",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552ebc5",
   "metadata": {},
   "source": [
    "# Test On Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f355ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_priors(ratings,plausible_rating, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    # rating_values = list(range(1, R + 1))\n",
    "    rating_values = plausible_rating\n",
    "\n",
    "    prior_userbased = [[0 for _ in range(num_items)] for _ in rating_values]\n",
    "    prior_itembased = [[0 for _ in range(num_users)] for _ in rating_values]\n",
    "\n",
    "    y_index = 0\n",
    "    for y in rating_values:\n",
    "        y_index = y_index\n",
    "\n",
    "        # Prior user-based (per item j)\n",
    "        for j in range(num_items):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for u in range(num_users):\n",
    "                r = ratings[u][j]   \n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_userbased[y_index][j] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "\n",
    "        # Prior item-based (per user u)\n",
    "        for u in range(num_users):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for j in range(num_items):\n",
    "                r = ratings[u][j]\n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_itembased[y_index][u] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "        y_index = y_index + 1\n",
    "\n",
    "    return prior_userbased, prior_itembased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_userbased(ratings, u, i, y, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Iu = [j for j in range(num_items) if j != i and ratings[u][j] != 0]\n",
    "    product = 1.0\n",
    "\n",
    "    for j in Iu:\n",
    "        k = ratings[u][j]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        for v in range(num_users):\n",
    "            if ratings[v][i] == y:\n",
    "                if ratings[v][j] != 0:\n",
    "                    count_cond += 1\n",
    "                    if ratings[v][j] == k:\n",
    "                        count_joint += 1\n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        # print(prob)\n",
    "        product *= prob\n",
    "    # print(\"======\")\n",
    "    # print(product, end=\"\\n\\n\")\n",
    "\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ae839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_itembased(ratings, u, i, y, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Ui = [v for v in range(num_users) if v != u and ratings[v][i] != 0]\n",
    "    product = 1.0\n",
    "\n",
    "    for v in Ui:\n",
    "        k = ratings[v][i]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        for j in range(num_items):\n",
    "            if ratings[u][j] == y:\n",
    "                if ratings[v][j] != 0:\n",
    "                    count_cond += 1\n",
    "                    if ratings[v][j] == k:\n",
    "                        count_joint += 1\n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        product *= prob\n",
    "\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30574ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(ratings, u, i, prior_userbased, prior_itembased,plausible_rating, alpha=0.01, mode='hybrid'):\n",
    "    scores = []\n",
    "    all_likelihood_user = []  \n",
    "    all_likelihood_item = []\n",
    "    all_combined = []\n",
    "    R = len(plausible_rating)  \n",
    "\n",
    "    y_index = 0\n",
    "    for y in plausible_rating:\n",
    "        prior_user = prior_userbased[y_index][i]\n",
    "        prior_item = prior_itembased[y_index][u]\n",
    "\n",
    "        likelihood_user = compute_likelihood_userbased(ratings, u, i, y, alpha, R)\n",
    "        likelihood_item = compute_likelihood_itembased(ratings, u, i, y, alpha, R)\n",
    "\n",
    "        all_likelihood_user.append(likelihood_user)\n",
    "        all_likelihood_item.append(likelihood_item)\n",
    "\n",
    "        if mode == 'user':\n",
    "            score = prior_user * likelihood_user\n",
    "        elif mode == 'item':\n",
    "            score = prior_item * likelihood_item\n",
    "        else:  # hybrid\n",
    "            len_Iu = sum(1 for j in range(len(ratings[0])) if ratings[u][j] != 0 and j != i)\n",
    "            len_Ui = sum(1 for v in range(len(ratings)) if v != u and ratings[v][i] != 0)\n",
    "\n",
    "            score_user = (prior_user * likelihood_user) ** (1 / (1 + len_Iu)) if len_Iu > 0 else 0\n",
    "            score_item = (prior_item * likelihood_item) ** (1 / (1 + len_Ui)) if len_Ui > 0 else 0\n",
    "            score = score_user * score_item\n",
    "\n",
    "        scores.append(score)\n",
    "        all_combined.append(score)\n",
    "        y_index = y_index + 1\n",
    "\n",
    "    # predicted_rating = scores.index(max(scores)) + 1\n",
    "    predicted_rating = plausible_rating[scores.index(max(scores))]\n",
    "\n",
    "    return predicted_rating, {\n",
    "        'scores': scores,\n",
    "        'likelihood_user': all_likelihood_user,\n",
    "        'likelihood_item': all_likelihood_item,\n",
    "        'combined_score': all_combined\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ecb48",
   "metadata": {},
   "source": [
    "# Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c437236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3cc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def load_movielens_1m(path=\"./ml-1m/ratings.dat\"):\n",
    "#     df = pd.read_csv(path, sep='::', engine='python', names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "#     num_users = df['user'].nunique()\n",
    "#     num_items = df['item'].nunique()\n",
    "\n",
    "#     user_map = {uid: idx for idx, uid in enumerate(df['user'].unique())}\n",
    "#     item_map = {iid: idx for idx, iid in enumerate(df['item'].unique())}\n",
    "\n",
    "#     ratings = np.zeros((num_users, num_items), dtype=int)\n",
    "#     for _, row in df.iterrows():\n",
    "#         u = user_map[row['user']]\n",
    "#         i = item_map[row['item']]\n",
    "#         ratings[u][i] = int(row['rating'])\n",
    "\n",
    "#     return ratings, user_map, item_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_filmtrust(path):\n",
    "    df = pd.read_csv(path, sep=' ', engine='python', names=['user', 'item', 'rating'])\n",
    "\n",
    "    num_users = df['user'].nunique()\n",
    "    num_items = df['item'].nunique()\n",
    "    # print(df['rating'].unique())    \n",
    "    plausible_rating = df['rating'].unique()\n",
    "\n",
    "    user_map = {uid: idx for idx, uid in enumerate(df['user'].unique())}\n",
    "    item_map = {iid: idx for idx, iid in enumerate(df['item'].unique())}\n",
    "\n",
    "    ratings = np.zeros((num_users, num_items), dtype=int)\n",
    "    for _, row in df.iterrows():\n",
    "        u = user_map[row['user']]\n",
    "        i = item_map[row['item']]\n",
    "        ratings[u][i] = row['rating']\n",
    "\n",
    "    return ratings, user_map, item_map, plausible_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b363f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_matrix(ratings, test_ratio=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    train = ratings.copy()\n",
    "    test = []\n",
    "\n",
    "    for u in range(ratings.shape[0]):\n",
    "        items_rated = np.where(ratings[u] > 0)[0]\n",
    "        if len(items_rated) == 0:\n",
    "            continue\n",
    "        test_size = max(1, int(len(items_rated) * test_ratio))\n",
    "        test_items = np.random.choice(items_rated, size=test_size, replace=False)\n",
    "        for i in test_items:\n",
    "            test.append((u, i, ratings[u][i]))  # simpan ground truth\n",
    "            train[u][i] = 0  # kosongkan di train\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_full, user_map, item_map = load_movielens_1m(\"./ml-1m/ratings.dat\")\n",
    "ratings_full, user_map, item_map,pR = load_filmtrust(\"./film-trust/ratings.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_r = len(pR)\n",
    "pR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pR.sort()\n",
    "pR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pR)):\n",
    "    # pR[i] = i\n",
    "    print(pR[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_train, test_set = train_test_split_matrix(ratings_full, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714335d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e391ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Komputasi prior\n",
    "prior_userbased, prior_itembased = compute_priors(ratings_train,pR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b315445",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_userbased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_itembased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prediksi dan evaluasi\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for u, i, actual in tqdm(test_set):\n",
    "    pred, _ = predict_rating(ratings_train, u, i, prior_userbased, prior_itembased,plausible_rating= pR, mode='hybrid')\n",
    "    y_true.append(actual)\n",
    "    y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3607e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
