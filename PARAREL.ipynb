{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d37daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import prod\n",
    "from decimal import Decimal, getcontext\n",
    "getcontext().prec = 13\n",
    "\n",
    "\n",
    "def compute_priors(ratings,plausible_rating, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    # rating_values = list(range(1, R + 1))\n",
    "    rating_values = plausible_rating\n",
    "\n",
    "    prior_userbased = [[0 for _ in range(num_items)] for _ in rating_values]\n",
    "    prior_itembased = [[0 for _ in range(num_users)] for _ in rating_values]\n",
    "\n",
    "    y_index = 0\n",
    "    for y in rating_values:\n",
    "        y_index = y_index\n",
    "\n",
    "        # Prior user-based (per item j)\n",
    "        for j in range(num_items):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for u in range(num_users):\n",
    "                r = ratings[u][j]   \n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_userbased[y_index][j] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "\n",
    "        # Prior item-based (per user u)\n",
    "        for u in range(num_users):\n",
    "            count_y = 0\n",
    "            count_nonzero = 0\n",
    "            for j in range(num_items):\n",
    "                r = ratings[u][j]\n",
    "                if r != 0:\n",
    "                    count_nonzero += 1\n",
    "                    if r == y:\n",
    "                        count_y += 1\n",
    "            prior_itembased[y_index][u] = (count_y + alpha) / (count_nonzero + alpha * R)\n",
    "        y_index = y_index + 1\n",
    "\n",
    "    return prior_userbased, prior_itembased\n",
    "\n",
    "def compute_likelihood_userbased(ratings, u, i, y, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Iu = [j for j in range(num_items) if j != i and ratings[u][j] != 0]\n",
    "    \n",
    "    # Precompute which users rated item i as y\n",
    "    users_with_y = [v for v in range(num_users) if ratings[v][i] == y]\n",
    "    \n",
    "    product = Decimal(1.0)\n",
    "    \n",
    "    for j in Iu:\n",
    "        k = ratings[u][j]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        \n",
    "        # Only iterate through users who rated item i as y\n",
    "        for v in users_with_y:\n",
    "            if ratings[v][j] != 0:\n",
    "                count_cond += 1\n",
    "                if ratings[v][j] == k:\n",
    "                    count_joint += 1\n",
    "        \n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        product *= Decimal(prob)\n",
    "    \n",
    "    return product\n",
    "\n",
    "def compute_likelihood_itembased(ratings, u, i, y, alpha=0.01, R=8):\n",
    "    num_users = len(ratings)\n",
    "    num_items = len(ratings[0])\n",
    "    Ui = [v for v in range(num_users) if v != u and ratings[v][i] != 0]\n",
    "    \n",
    "    # Precompute which items user u rated as y\n",
    "    items_with_y = [j for j in range(num_items) if ratings[u][j] == y]\n",
    "    \n",
    "    product = Decimal(1.0)\n",
    "    \n",
    "    for v in Ui:\n",
    "        k = ratings[v][i]\n",
    "        count_joint = 0\n",
    "        count_cond = 0\n",
    "        \n",
    "        # Only iterate through items rated as y by user u\n",
    "        for j in items_with_y:\n",
    "            if ratings[v][j] != 0:\n",
    "                count_cond += 1\n",
    "                if ratings[v][j] == k:\n",
    "                    count_joint += 1\n",
    "        \n",
    "        prob = (count_joint + alpha) / (count_cond + alpha * R)\n",
    "        product *= Decimal(prob)\n",
    "    \n",
    "    return product\n",
    "\n",
    "\n",
    "def predict_rating(ratings, u, i, prior_userbased, prior_itembased,plausible_rating, alpha=1):\n",
    "    scores = []\n",
    "    all_likelihood_user = []  \n",
    "    all_likelihood_item = []\n",
    "    R = len(plausible_rating)  \n",
    "    \n",
    "    \n",
    "    len_Iu = sum(1 for j in range(len(ratings[0])) if ratings[u][j] != 0)\n",
    "    len_Ui = sum(1 for v in range(len(ratings)) if ratings[v][i] != 0)\n",
    "\n",
    "    y_index = 0\n",
    "    for y in plausible_rating:\n",
    "        prior_user = prior_userbased[y_index][i]\n",
    "        prior_item = prior_itembased[y_index][u]\n",
    "    \n",
    "\n",
    "        likelihood_user = compute_likelihood_userbased(ratings, u, i, y, alpha, R)\n",
    "        likelihood_item = compute_likelihood_itembased(ratings, u, i, y, alpha, R)\n",
    "        \n",
    "        # simpan sebagai justifikasi\n",
    "        all_likelihood_user.append(likelihood_user)\n",
    "        all_likelihood_item.append(likelihood_item)\n",
    "        \n",
    "        \n",
    "        score_item = (Decimal(prior_item) * likelihood_item) ** Decimal(1 / (1 + len_Ui)) if len_Ui > 0 else 0\n",
    "        score_user = (Decimal(prior_user) * likelihood_user) ** Decimal(1 / (1 + len_Iu)) if len_Iu > 0 else 0\n",
    "\n",
    "        score = score_user * score_item\n",
    "\n",
    "        scores.append(score)\n",
    "        y_index += 1\n",
    "\n",
    "    predicted_rating = plausible_rating[scores.index(max(scores))]\n",
    "\n",
    "    return predicted_rating, {\n",
    "        'scores': scores,\n",
    "        'likelihood_user': all_likelihood_user,\n",
    "        'likelihood_item': all_likelihood_item\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# full_df = pd.read_csv('./film-trust/ratings.txt', sep=' ', names=['user', 'item', 'rating'])\n",
    "# user_ids = full_df['user'].unique()\n",
    "# item_ids = full_df['item'].unique()\n",
    "# user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "# item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
    "\n",
    "# # Split dataset\n",
    "# full_df['user_idx'] = full_df['user'].map(user_map)\n",
    "# full_df['item_idx'] = full_df['item'].map(item_map)\n",
    "# train_df, test_df = train_test_split(full_df[['user_idx', 'item_idx', 'rating']], test_size=0.2, random_state=42)\n",
    "\n",
    "# print(f\"\\nTrain set: {len(train_df)} ratings ({len(train_df)/len(full_df)*100:.1f}%)\")\n",
    "# print(f\"Test set: {len(test_df)} ratings ({len(test_df)/len(full_df)*100:.1f}%)\")\n",
    "# train_df.to_csv('./film-trust/train.txt', sep=' ', header=False, index=False)\n",
    "# test_df.to_csv('./film-trust/test.txt', sep=' ', header=False, index=False)\n",
    "\n",
    "\n",
    "temp_df = pd.read_csv(\"./film-trust/ratings.txt\", sep=' ', engine='python', names=['rating'])\n",
    "plausible_rating = temp_df['rating'].unique()\n",
    "plausible_rating.sort()\n",
    "plausible_rating\n",
    "\n",
    "pR = plausible_rating\n",
    "num_r = len(pR)\n",
    "num_r\n",
    "\n",
    "\n",
    "def load_filmtrust_train_make_matrix(path, full_ratings):\n",
    "    df = pd.read_csv(path, sep=' ', engine='python', names=['user', 'item', 'rating'])\n",
    "    df_full = pd.read_csv(full_ratings, sep=' ', engine='python', names=['user', 'item', 'rating'])\n",
    "\n",
    "    num_users = df_full['user'].nunique()\n",
    "    num_items = df_full['item'].nunique()\n",
    "\n",
    "    user_map = {uid: idx for idx, uid in enumerate(df['user'].unique())}\n",
    "    item_map = {iid: idx for idx, iid in enumerate(df['item'].unique())}\n",
    "\n",
    "    ratings = np.zeros((num_users, num_items))\n",
    "    for _, row in df.iterrows():\n",
    "        u = user_map[row['user']]\n",
    "        i = item_map[row['item']]\n",
    "        ratings[u][i] = row['rating']\n",
    "\n",
    "    return ratings, user_map, item_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_test_ratings(path):\n",
    "    data = np.loadtxt(path, dtype={'names': ('u', 'i', 'r'), 'formats': (int, int, float)})\n",
    "    test = np.array(\n",
    "        [(int(row[0])-1, int(row[1])-1, float(row[2])) for row in data],\n",
    "        dtype=[('u', int), ('i', int), ('r', float)]\n",
    "    )\n",
    "    return test\n",
    "\n",
    "ratings_train, user_map, item_map = load_filmtrust_train_make_matrix(\"./film-trust/train.txt\",\"./film-trust/ratings.txt\")\n",
    "test_set = load_test_ratings(\"./film-trust/test.txt\")\n",
    "\n",
    "\n",
    "prior_userbased, prior_itembased = compute_priors(ratings_train,pR)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba6461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:33<00:00, 10.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_in_batches(test_set, ratings, prior_userbased, prior_itembased, pR, batch_size=1000):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    n_batches = ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    for batch_idx in tqdm(range(n_batches)):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        batch = test_set[start:end]\n",
    "        \n",
    "        for u, i, actual in batch:\n",
    "            pred, _ = predict_rating(ratings, u, i, prior_userbased, prior_itembased, pR)\n",
    "            y_true.append(actual)\n",
    "            y_pred.append(pred)\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# Gunakan dengan:\n",
    "y_true, y_pred = predict_in_batches(test_set, ratings_train, prior_userbased, prior_itembased, pR, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a798082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1.0002112676056338\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_error = 0\n",
    "n = len(y_true)\n",
    "\n",
    "for actual, pred in zip(y_true, y_pred):\n",
    "    total_error += abs(actual - pred)\n",
    "\n",
    "mae = total_error / n\n",
    "print(f\"MAE : {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e83ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "df_results.to_csv('./film-trust/predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
